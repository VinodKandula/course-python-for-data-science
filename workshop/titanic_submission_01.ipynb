{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import LabelEncoder, MinMaxScaler, StandardScaler, OneHotEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data = pd.read_csv('train.csv')\n",
    "testing_data = pd.read_csv('test.csv')\n",
    "p_id = testing_data['PassengerId']\n",
    "data = pd.concat([training_data, testing_data])\n",
    "\n",
    "data.drop('PassengerId', axis=1, inplace=True)\n",
    "survived = data['Survived'].dropna()\n",
    "data['Survived'].fillna(-1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_hot(dataframe, name):\n",
    "    dataframe = pd.concat([dataframe, pd.get_dummies(dataframe[name])\n",
    "                           .rename(columns=lambda x: name + str(x))], axis=1)\n",
    "    return dataframe.drop(name, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocessing(data) :\n",
    "    # Cabin\n",
    "    data['Cabin'].fillna('U0', inplace=True)\n",
    "    data['CabinSection'] = LabelEncoder().fit_transform(data['Cabin'].map(lambda x: x[0]))\n",
    "    \n",
    "    data['CabinDistance'] = data['Cabin'].map(lambda x: x[1:])\n",
    "    data['CabinDistance'] = data['CabinDistance'].map(lambda x: x.split(' ')[0])\n",
    "    data['CabinDistance'].where(data['CabinDistance'] != '', '0', inplace=True)\n",
    "    data['CabinDistance'] = data['CabinDistance'].map(lambda x: int(x))\n",
    "    data['CabinDistance'] = StandardScaler().fit_transform(data['CabinDistance'].values.reshape(-1, 1))\n",
    "    \n",
    "    # Sex\n",
    "    data['Sex'] = LabelEncoder().fit_transform(data['Sex'])\n",
    "    \n",
    "    # Embarked\n",
    "    data['Embarked'].fillna('S', inplace=True)\n",
    "    data['Embarked'] = LabelEncoder().fit_transform(data['Embarked'])\n",
    "    \n",
    "    # Name\n",
    "    data['Name'] = data['Name'].map(lambda x: x.split(',')[1].split('.')[0])\n",
    "    data['Name'] = LabelEncoder().fit_transform(data['Name'])\n",
    "    \n",
    "    # Fare\n",
    "    data['Fare'].fillna(-1, inplace=True)\n",
    "    medians = dict()\n",
    "    for pclass in data['Pclass'].unique():\n",
    "        median = data.Fare[(data[\"Fare\"] != -1) & (data['Pclass'] == pclass)].median()\n",
    "        medians[pclass] = median\n",
    "    for index, row in data.iterrows():\n",
    "        if row['Fare'] == -1:\n",
    "            data.loc[index, 'Fare'] = medians[row['Pclass']]\n",
    "    data['Fare'] = StandardScaler().fit_transform(data['Fare'].values.reshape(-1, 1))\n",
    "    \n",
    "    # Age\n",
    "    data['Age'].fillna(-1, inplace=True)\n",
    "    medians = dict()\n",
    "    for title in data['Name'].unique():\n",
    "        median = data.Age[(data[\"Age\"] != -1) & (data['Name'] == title)].median()\n",
    "        medians[title] = median\n",
    "    for index, row in data.iterrows():\n",
    "        if row['Age'] == -1:\n",
    "            data.loc[index, 'Age'] = medians[row['Name']]\n",
    "            \n",
    "    data['Age'] = StandardScaler().fit_transform(data['Age'].values.reshape(-1, 1))\n",
    "    \n",
    "    for index, row in data.iterrows():\n",
    "        ticket = row['Ticket']\n",
    "        sibsp = row['SibSp']\n",
    "        parch = row['Parch']\n",
    "\n",
    "        if sibsp > 0 or parch > 0:\n",
    "            ages = list()\n",
    "            for index2, row2 in data[data['Ticket'] == ticket].iterrows():\n",
    "                ages.append(row2['Age'])\n",
    "            data.loc[index, 'Age2'] = min(ages)\n",
    "\n",
    "        else:\n",
    "            data.loc[index, 'Age2'] = row['Age']\n",
    "            \n",
    "    data['Age2'] = StandardScaler().fit_transform(data['Age2'].values.reshape(-1, 1))\n",
    "    \n",
    "    # Prefix\n",
    "    died_titles = ('Don', 'Rev', 'Capt', 'Jonkheer')\n",
    "    survived_titles = ('Mme', 'Ms', 'Lady', 'Sir', 'Mlle', 'the Countess')\n",
    "    data['Title_Died'] = data['Name'].apply(lambda x: int(x in died_titles))\n",
    "    data['Title_Survived'] = data['Name'].apply(lambda x: int(x in survived_titles))\n",
    "\n",
    "    for title in ('Mr', 'Mrs', 'Miss', 'Master', 'Dr', 'Major', 'Col'):\n",
    "        data['Title_{}'.format(title)] = data['Name'].apply(lambda x: int(x == title))\n",
    "        \n",
    "    data.drop('Name', axis=1, inplace=True)\n",
    "    \n",
    "    data = one_hot(data, 'Pclass')\n",
    "    \n",
    "    # Ticket\n",
    "    data.drop('Ticket', axis=1, inplace=True)\n",
    "    \n",
    "    data.drop('Cabin', axis=1, inplace=True)\n",
    "    \n",
    "    \n",
    "    \n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/sklearn/utils/validation.py:429: DataConversionWarning: Data with input dtype int64 was converted to float64 by StandardScaler.\n",
      "  warnings.warn(msg, _DataConversionWarning)\n",
      "/opt/conda/lib/python3.6/site-packages/ipykernel_launcher.py:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \n",
      "/opt/conda/lib/python3.6/site-packages/ipykernel_launcher.py:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  import sys\n"
     ]
    }
   ],
   "source": [
    "processed_data = preprocessing(data)\n",
    "training_data2 = processed_data[data['Survived'] != -1]\n",
    "testing_data2 = processed_data[data['Survived'] == -1]\n",
    "\n",
    "\n",
    "training_data2.drop('Survived', axis=1, inplace=True)\n",
    "testing_data2.drop('Survived', axis=1, inplace=True)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(training_data2, survived, test_size=0.20, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.754189944134\n",
      "0.782122905028\n",
      "0.754189944134\n",
      "0.810055865922\n",
      "0.810055865922\n",
      "0.798882681564\n",
      "0.776536312849\n",
      "0.743016759777\n",
      "0.430167597765\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:695: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.gaussian_process import GaussianProcessClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\n",
    "\n",
    "models = [\n",
    "    KNeighborsClassifier(3),\n",
    "    SVC(kernel=\"linear\", C=0.025),\n",
    "    SVC(gamma=2, C=1),\n",
    "    DecisionTreeClassifier(max_depth=10),\n",
    "    RandomForestClassifier(n_estimators=100),\n",
    "    MLPClassifier(),\n",
    "    AdaBoostClassifier(),\n",
    "    GaussianNB(),\n",
    "    QuadraticDiscriminantAnalysis()\n",
    "]\n",
    "\n",
    "for model in models:\n",
    "    model.fit(X_train, y_train)\n",
    "    score = model.score(X_test, y_test)\n",
    "    print(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/sklearn/neural_network/multilayer_perceptron.py:563: ConvergenceWarning: Stochastic Optimizer: Maximum iterations reached and the optimization hasn't converged yet.\n",
      "  % (), ConvergenceWarning)\n"
     ]
    }
   ],
   "source": [
    "models = [\n",
    "    RandomForestClassifier(n_estimators=100),\n",
    "    MLPClassifier(),\n",
    "]\n",
    "\n",
    "index = 1\n",
    "for model in models:\n",
    "    model.fit(training_data2, survived)\n",
    "    prediction = model.predict(testing_data2)\n",
    "    \n",
    "    submission = pd.DataFrame({\n",
    "        \"PassengerId\": testing_data[\"PassengerId\"],\n",
    "        \"Survived\": prediction.astype(int)\n",
    "    })\n",
    "    submission.to_csv('submission{}.csv'.format(index), index=False)\n",
    "#     np.savetxt('submission{}.csv'.format(index), prediction, delimiter=\",\")\n",
    "    index += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
